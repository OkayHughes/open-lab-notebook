---
date: 2021-08-16
tags:
  - posts
  - ncl
eleventyNavigation:
  key: Notes 2023.09.11
  parent: CLaSP 586
layout: layouts/post.njk
---

## Multiple random variables redux:

Rank correlation coefficient:
`$$r' = 1 - 6 \sum_{i} \frac{d_i^2}{N(N^2-1)} $$`

Joint distribution: 
`$$
\probp([x_1, x_2] \times [y_1, y_2]) = \iint_{I_x \times I_y} p(x, y) \intd{y} \intd{x}
$$`

NMarginal distribution:
`$$
\probp([x_1, x_2]) = \int_{x_1}^{x_2} \int_{\mathbb{R}} p(x, y) \intd{y} \intd{x}
$$`

e.g. for a bivariate normal
`$$$
p(x, y) = \frac{1}{\pi \sigma_1 \sigma_2 \sqrt{1-r^2}} \exp \left[-\frac{1}{2(1-r)^2}\left(\frac{(x-\mu_1)^2}{\sigma_1^2} + \frac{(y-\mu_2)^2}{\sigma_2^2} - 2r \frac{(x-\mu_1)(x-\mu_2)}{\sigma_1 \sigma_2} \right) \right]
$$$`.
### "Independence":

* Statistical independence: `$$p(x, y) = p(x)p(y) $$`. I.e. the probability of events
* Linear independence: `$$r=0$$`, i.e. principal axes of level sets of pdf are orthogonal. 
* Physical independence: causal statement from domain knowledge.



### Estimation of pdfs:
* Histograms: choice of parameters (e.g., bin size)
  * Naively can estimate sensitivity to bin size (even in eyeball norm!)
  * Exercise: take a large-ish climate dataset (e.g., 300hPa tropical relative humidity) ~300,000 samples. Take 3000 datapoint subset. Make histograms.
* Kernel density estimation
  * Many parameters, many methods. 
  * Can get fairly rigorous convergence results under mild assumptions (can these be tested directly on data?)
### Correlation and causality:
* A statistically significant correlation should be analyzed in context of, e.g., length of data record.
  * A simple scatter plot can serve as a gut check (n.b. I use this instead of sanity check) for correctness.
  * Do you have a physically plausible interpretation of correlation? A curious correlation can serve as a start of inquiry, but it is almost never proof in and of itself.
  
  
## Lecture 03: Statistics


### Gamma function:
`$$$
\Gamma(z) \equiv \int_0^\infty t^{z-1} e^{-t} \intd{t}
$$$`
`$$$ 
\Gamma(n) = (n-1)! = \prod_{i=1}^{n-1} i 
$$$`

## Useful distributions:
* Suppose we have an infinite population `$$\sim \mathcal{N}(\mu, \sigma)$$`,
then the standard deviation of the average of `$$N$$` independent samples is `$$ \frac{\sigma}{\sqrt{N}}$$`
* Z-statistics (one variable)
`$$
z = \frac{\bar{x}-\mu}{\sigma_{\bar{x}}} = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}}
$$`
* Z-statistics: (two variable)
`$$
z = \frac{\bar{x}_1 - \bar{x}_2 - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2}{N_1} + \frac{\sigma_2^2}{N_2}}}
$$`

This works in the sense that `$$\bar{x}$$` is a probability distribution on `$$S^N$$` which is an estimator for `$$\mu$$`.
The variance diminishes as we take more I.I.D. samples.




